{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "#### by **Ivan Alducin**\n",
    "<p><img src=\"https://preview.redd.it/rfgtsej8fhv71.jpg?auto=webp&s=99a5d000ff2baaac79a8d15c7135c3677f105159\" width=\"1000\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "<p>Vamos a trabajar con el conjunto de datos de <code>Heart Attack</code>, el objetivo es predecir bajo que escenario es más probable que un paciente pueda tener un ataque al corazón  Un experto en medicina cardiovasuclar puede predecir esto sin hacer uso de <i>Machine Learning</i>, pero probablemente no instantáneamente, ¡y ciertamente no si estamos tratando con cientos o miles de muestras!.\n",
    "    \n",
    "A continuación una breve explicación de las variables del dataset:\n",
    "    \n",
    "- <b>age:</b> Age of the patient\n",
    "- <b>sex:</b> Sex of the patient\n",
    "- <b>cp:</b> Chest pain type ~ 0 = Typical Angina, 1 = Atypical Angina, 2 = Non-anginal Pain, 3 = Asymptomatic\n",
    "- <b>trtbps:</b> Resting blood pressure (in mm Hg)\n",
    "- <b>chol:</b> Cholestoral in mg/dl fetched via BMI sensor\n",
    "- <b>fbs:</b> (fasting blood sugar > 120 mg/dl) ~ 1 = True, 0 = False\n",
    "- <b>restecg:</b> Resting electrocardiographic results ~ 0 = Normal, 1 = ST-T wave normality, 2 = Left ventricular hypertrophy\n",
    "- <b>thalachh:</b> Maximum heart rate achieved\n",
    "- <b>oldpeak:</b> Previous peak\n",
    "- <b>slp:</b> Slope\n",
    "- <b>caa:</b> Number of major vessels\n",
    "- <b>thall:</b> Thalium Stress Test result ~ (0,3)\n",
    "- <b>exng:</b> Exercise induced angina ~ 1 = Yes, 0 = No\n",
    "- <b>output:</b>  Target variable</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
      "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
      "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
      "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
      "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
      "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
      "\n",
      "   caa  thall  output  \n",
      "0    0      1       1  \n",
      "1    0      2       1  \n",
      "2    0      2       1  \n",
      "3    0      2       1  \n",
      "4    0      2       1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trtbps    303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalachh  303 non-null    int64  \n",
      " 8   exng      303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slp       303 non-null    int64  \n",
      " 11  caa       303 non-null    int64  \n",
      " 12  thall     303 non-null    int64  \n",
      " 13  output    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "None\n",
      "              age         sex          cp      trtbps        chol         fbs  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
      "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
      "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
      "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
      "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
      "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
      "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
      "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
      "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
      "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
      "\n",
      "            thall      output  \n",
      "count  303.000000  303.000000  \n",
      "mean     2.313531    0.544554  \n",
      "std      0.612277    0.498835  \n",
      "min      0.000000    0.000000  \n",
      "25%      2.000000    0.000000  \n",
      "50%      2.000000    1.000000  \n",
      "75%      3.000000    1.000000  \n",
      "max      3.000000    1.000000  \n",
      "sex\n",
      "1    207\n",
      "0     96\n",
      "Name: count, dtype: int64\n",
      "cp\n",
      "0    143\n",
      "2     87\n",
      "1     50\n",
      "3     23\n",
      "Name: count, dtype: int64\n",
      "fbs\n",
      "0    258\n",
      "1     45\n",
      "Name: count, dtype: int64\n",
      "restecg\n",
      "1    152\n",
      "0    147\n",
      "2      4\n",
      "Name: count, dtype: int64\n",
      "exng\n",
      "0    204\n",
      "1     99\n",
      "Name: count, dtype: int64\n",
      "output\n",
      "1    165\n",
      "0    138\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Archivo Heart Attack.csv - ¿Cuales son los factores que pueden incrementar o disminuir la probabilidad de un ataque al corazón?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Heart Attack.csv')\n",
    "\n",
    "# Explorar las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Verificar la estructura de los datos\n",
    "print(df.info())\n",
    "\n",
    "# Descripción estadística de las variables numéricas\n",
    "print(df.describe())\n",
    "\n",
    "# Revisar la distribución de las variables categóricas\n",
    "print(df['sex'].value_counts())\n",
    "print(df['cp'].value_counts())\n",
    "print(df['fbs'].value_counts())\n",
    "print(df['restecg'].value_counts())\n",
    "print(df['exng'].value_counts())\n",
    "print(df['output'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer EDA (Exploratory Data Analysis) suele ser un tanto laborioso dependiendo del detalle al que se quiera llevar, pero prueba la siguiente librería, puede que a partir de ahora, tu EDA sea más fácil ;)\n",
    "!pip install dataprep\n",
    "from dataprep.eda import create_report\n",
    "\n",
    "create_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors\n",
    "<p>Habiendo hecho un Análisis Exploratorio de los factores que pueden o no tener más posibilidad de un ataque al corazón, es hora de crear tu primer clasificador!!! usando el algoritmo de k-NN.\n",
    "    \n",
    "<b>Nota</b>: es importante garantizar que los datos esten en el formato requerido por la librería de <code>scikit-learn</code>. La información debe estar en una matriz en la que cada columna sea una variable y cada fila una observación diferente, en este caso, el registro de análisis clinico por paciente. Y la variable objetivo debe ser una sola columna con el mismo número de observaciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la librería para un clasificador k-NN de sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crea dos arreglos \"X\", \"y\" que contengan los valores de las variables independientes y la variable objetivo\n",
    "x = df.drop(columns=['output'])  \n",
    "y = df['output']  \n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# Crea un clasificador k-NN con 6 vecinos\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Ajusta el clasificador a las variables\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Ajusta el clasificador a las variables de entrenamiento\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el rendimiento en el conjunto de prueba\n",
    "score = knn.score(X_test, y_test)\n",
    "print(f\"score: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción\n",
    "<p>Una vez que entrenamos al clasificador k-NN, ahora lo podemos usar para predecir un nuevo registro. Para este caso,  no hay datos sin clasificar disponibles ya que todos se usaron para entrenar al modelo. Para poder calcular una predicción, vamos a usar el método <code>.predict()</code> pero, para esto vamos a simular una observación completamente nueva</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un arreglo simulando una observación\n",
    "X_new = [[45, 1, 2, 140, 240, 0, 0, 130, 1.5, 2, 0, 3, 0]]\n",
    "\n",
    "# Predice la clasificación para el arreglo que creaste\n",
    "y_new_pred = knn.predict(X_new)\n",
    "print(\"Predición: \",(y_new_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de digitos\n",
    "<p>Hasta ahora, solo hemos realizado una clasificación binaria, ya que la variable objetivo tenía dos resultados posibles. En los siguientes ejercicios, trabajarás con el conjunto de datos de reconocimiento de dígitos MNIST, que tiene 10 clases, ¡los dígitos del 0 al 9! Una versión reducida del conjunto de datos <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST</a> es uno de los conjuntos de datos incluidos en <code>scikit-learn</code>\n",
    "\n",
    "Cada muestra de este conjunto de datos es una imagen de 28x28 que representa un dígito escrito a mano. Cada píxel está representado por un número entero en el rango de 1 a 784, lo que indica niveles variables de negro.\n",
    "\n",
    "<p><img src=\"https://miro.medium.com/max/1400/1*hVdoiW35FXUE-fZ0HI30Tw.jpeg\" width=\"350\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el archivo de MNIST\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una variable 'cols' para hacer referencia a todas las columnas que contienen la palabra 'pixel'\n",
    "cols = [f'pixel_{i}' for i in range(1, 785)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a imprimir un digito\n",
    "i =  0\n",
    "print(\"El número es:\", digits.target[i])\n",
    "plt.imshow(digits.data[i].reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test\n",
    "<p>Una de las principales diferencias entre la Estadística Clasica y el <i>Machine Learning</i> es la división del conjunto de datos en conjuntos de entrenamiento y prueba, con el objetivo de medir y cuantificar la precisión y el nivel de error en los datos que de alguna manera el modelo <i>\"No ha visto\"</i>. A continuación crearemos nuestros conjuntos de entrenamiento y prueba con el método <code>train_test_split</code> y mediremos cual es el nivel de precisión de nuestro modelo. El objetivo es <b>predecir cual es el digito dada una imagen</b>!!!. Para lo cual entrenaremos un clasificador <i>k-NN</i> a los datos de entrenamiento y luego calcularemos su precisión usando el método <code>accuracy_score()</code> en los datos de prueba ¿Como crees que en un modelo de Clasificación se calcule su precisión?. Parece bastante dificil, pero no lo es ;)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la librería para entrenamiento y prueba de datos y la librería para calcular la precisión\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea los arreglos para las variables independientes y la variable objetivo\n",
    "X = digits.data  \n",
    "y = digits.target  \n",
    "\n",
    "# Divide los arreglos anteriores en conjuntos de training y test en una proporcion del 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Instancia un clasificador k-NN con 14 vecinos\n",
    "knn = KNeighborsClassifier(n_neighbors=14)\n",
    "\n",
    "# Ajusta (Entrenamiento) el clasificador en el conjunto de entrenamiento\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Calcular las predicciones sobre el conjunto de prueba\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Verificar la precisión del modelo \n",
    "print(\"Accuracy score:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de tu imagen\n",
    "<p>Con todo lo anterior, podemos hacer el reconocimiento de cualquier digito que dibujes, ¿Estás list@?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a visualizar la imagen de un número que vas a crear en tu computador con la aplicación de paint, ésta imagen debe de tener un fondo negro y ser pintada en blanco, encontrarás un ejemplo en el repositorio\n",
    "image = plt.imread(\"C:/Users/adyce/OneDrive/Escritorio/Data Science/EBAC.png\") # Coloca aquí la ruta de la imagen que hayas creado en formato jpg o png\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con esta libreria transformaremos la imagen creada a un formato de 28x28 pixeles\n",
    "from PIL import Image\n",
    "pil = Image.open(\"C:/Users/adyce/OneDrive/Escritorio/Data Science/EBAC.png\")\n",
    "image_resize = pil.resize((28, 28))\n",
    "\n",
    "# Vamos transformar la nueva imagen en un array donde se almacenara la información de los pixeles\n",
    "pixels = np.asarray(image_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesitamos hacer algunas configuraciones a la imagen debido al formato de datos que esta alimentando al modelo y a la configuración de sklearn\n",
    "arr = pixels.transpose(2, 0, 1).reshape(-1, pixels.shape[1])[0:28]\n",
    "\n",
    "image_final = arr.ravel().reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la predicción del modelo con el número que creaste, ¿Fue la clasificación correcta? :O\n",
    "print(\"El número es:\", image_final)\n",
    "plt.imshow(arr, cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit and Underfit\n",
    "<p>¿Cual es mi numero ideal para elegir el parametro <i>k</i>? Vamos a calcular los valores de precisión para los conjuntos e entrenamiento y prueba para una rango de valores k. Al observar cómo difieren estos valores podremos observar cual es el mejor parametro sin caer en un <i>Overfit</i> o un <i>Underfit</i>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coniguración de arreglos iniciales\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop para diferentes valores de k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Clasificador k-NN para el parametro k\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Ajuste del clasificador al dataset de entrenamiento\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Calculo de precision sobre el dataset de entrenamiento\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Calculo de precision sobre el dataset de prueba\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "# Grafico para encontrar un valor optimo de k\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.title('k-NN: by Number of Neighbors')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "<p>Haz la predicción de tu imagen, pero esta vez por medio de una Regresión Logística, ¿Cuál de los dos modelos te da mejores resultados?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "# Cargar el conjunto de datos de dígitos\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de regresión logística\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Ajustar el clasificador al conjunto de entrenamiento\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Calcular las predicciones sobre el conjunto de prueba\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Verificar la precisión del modelo\n",
    "print(\"Accuracy of Logistic Regression: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# Vamos a visualizar la imagen de un número que vas a crear en tu computador con la aplicación de paint\n",
    "# Esta imagen debe de tener un fondo negro y ser pintada en blanco\n",
    "\n",
    "# Coloca aquí la ruta de la imagen que hayas creado en formato jpg o png\n",
    "image = plt.imread('ruta_de_tu_imagen.jpg')\n",
    "plt.imshow(image)\n",
    "\n",
    "# Con esta libreria transformamos la imagen creada a un formato de 28x28 pixeles\n",
    "pil = Image.open('ruta_de_tu_imagen.jpg')\n",
    "image_resize = pil.resize((28, 28))\n",
    "\n",
    "# Vamos a transformar la nueva imagen en un array donde se almacenara la información de los pixeles\n",
    "pixels = np.asarray(image_resize.convert('L'))  # Convertir a escala de grises\n",
    "\n",
    "# Necesitamos hacer algunas configuraciones a la imagen debido al formato de datos que está alimentando al modelo\n",
    "image_final = pixels.reshape(1, -1)\n",
    "\n",
    "# Realizamos la predicción del modelo\n",
    "y_new_pred = log_reg.predict(image_final)\n",
    "\n",
    "# Mostramos la predicción\n",
    "print(\"Prediction: \", y_new_pred[0])\n",
    "\n",
    "# Visualizamos la imagen final\n",
    "plt.imshow(pixels, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
